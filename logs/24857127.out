Experiment arguments: {'mode': 'train', 'epochs': 500, 'beta': 2.0, 'neg_factor': 5.0, 'device': 'cuda', 'hidden_dim': 64, 'latent_dim': 32, 'num_rounds': 5, 'gnn_layers': 1, 'decoder': 'gnn', 'checkpoint': './experiments/gnn_hd64_ld32_nr5_ep500_b2.0_nf5.0/model.pt', 'log_dir': './experiments/gnn_hd64_ld32_nr5_ep500_b2.0_nf5.0/logs', 'fig_dir': './experiments/gnn_hd64_ld32_nr5_ep500_b2.0_nf5.0/figures'}
Loaded 171 training hashes.
Epoch 0001 │ loss=1.9792 │ lr=1.0e-03
Epoch 0005 │ loss=1.1490 │ lr=1.0e-03
Epoch 0010 │ loss=1.1337 │ lr=1.0e-03
Epoch 0015 │ loss=1.1792 │ lr=1.0e-03
Epoch 0020 │ loss=1.2453 │ lr=1.0e-03
Epoch 0025 │ loss=1.3141 │ lr=1.0e-03
Epoch 0030 │ loss=1.3729 │ lr=1.0e-03
Epoch 0035 │ loss=1.4230 │ lr=5.0e-04
Epoch 0040 │ loss=1.5027 │ lr=5.0e-04
Epoch 0045 │ loss=1.5562 │ lr=5.0e-04
Epoch 0050 │ loss=1.6112 │ lr=5.0e-04
Epoch 0055 │ loss=1.6134 │ lr=2.5e-04
Epoch 0060 │ loss=1.5978 │ lr=2.5e-04
Epoch 0065 │ loss=1.6195 │ lr=2.5e-04
Epoch 0070 │ loss=1.5761 │ lr=2.5e-04
Epoch 0075 │ loss=1.5880 │ lr=1.3e-04
Epoch 0080 │ loss=1.5541 │ lr=1.3e-04
Epoch 0085 │ loss=1.5781 │ lr=1.3e-04
Epoch 0090 │ loss=1.5544 │ lr=1.3e-04
Epoch 0095 │ loss=1.5380 │ lr=6.3e-05
Epoch 0100 │ loss=1.5540 │ lr=6.3e-05
Epoch 0105 │ loss=1.5232 │ lr=6.3e-05
Epoch 0110 │ loss=1.5446 │ lr=6.3e-05
Epoch 0115 │ loss=1.5385 │ lr=6.3e-05
Epoch 0120 │ loss=1.5231 │ lr=3.1e-05
Epoch 0125 │ loss=1.5435 │ lr=3.1e-05
Epoch 0130 │ loss=1.5330 │ lr=3.1e-05
Epoch 0135 │ loss=1.5362 │ lr=3.1e-05
Epoch 0140 │ loss=1.5209 │ lr=1.6e-05
Epoch 0145 │ loss=1.5211 │ lr=1.6e-05
Epoch 0150 │ loss=1.5265 │ lr=1.6e-05
Epoch 0155 │ loss=1.5486 │ lr=1.6e-05
Epoch 0160 │ loss=1.5255 │ lr=7.8e-06
Epoch 0165 │ loss=1.5207 │ lr=7.8e-06
Epoch 0170 │ loss=1.5537 │ lr=7.8e-06
Epoch 0175 │ loss=1.5350 │ lr=7.8e-06
Epoch 0180 │ loss=1.5329 │ lr=3.9e-06
Epoch 0185 │ loss=1.5260 │ lr=3.9e-06
Epoch 0190 │ loss=1.5260 │ lr=3.9e-06
Epoch 0195 │ loss=1.5471 │ lr=3.9e-06
Epoch 0200 │ loss=1.5431 │ lr=2.0e-06
Epoch 0205 │ loss=1.5122 │ lr=2.0e-06
Epoch 0210 │ loss=1.5284 │ lr=2.0e-06
Epoch 0215 │ loss=1.5205 │ lr=2.0e-06
Epoch 0220 │ loss=1.5229 │ lr=2.0e-06
Epoch 0225 │ loss=1.5249 │ lr=9.8e-07
Epoch 0230 │ loss=1.5206 │ lr=9.8e-07
Epoch 0235 │ loss=1.5345 │ lr=9.8e-07
Epoch 0240 │ loss=1.5196 │ lr=9.8e-07
Epoch 0245 │ loss=1.5146 │ lr=4.9e-07
Epoch 0250 │ loss=1.5113 │ lr=4.9e-07
Epoch 0255 │ loss=1.5165 │ lr=4.9e-07
Epoch 0260 │ loss=1.5415 │ lr=4.9e-07
Epoch 0265 │ loss=1.5062 │ lr=2.4e-07
Epoch 0270 │ loss=1.5116 │ lr=2.4e-07
Epoch 0275 │ loss=1.5079 │ lr=2.4e-07
Epoch 0280 │ loss=1.5323 │ lr=2.4e-07
Epoch 0285 │ loss=1.5434 │ lr=1.2e-07
Epoch 0290 │ loss=1.5254 │ lr=1.2e-07
Epoch 0295 │ loss=1.5399 │ lr=1.2e-07
Epoch 0300 │ loss=1.5433 │ lr=1.2e-07
Epoch 0305 │ loss=1.4882 │ lr=6.1e-08
Epoch 0310 │ loss=1.5408 │ lr=6.1e-08
Epoch 0315 │ loss=1.5167 │ lr=6.1e-08
Epoch 0320 │ loss=1.5317 │ lr=6.1e-08
Epoch 0325 │ loss=1.5315 │ lr=6.1e-08
Epoch 0330 │ loss=1.5383 │ lr=3.1e-08
Epoch 0335 │ loss=1.5238 │ lr=3.1e-08
Epoch 0340 │ loss=1.5350 │ lr=3.1e-08
